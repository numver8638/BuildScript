/*
 * Lexer.KeywordTable.cpp
 * - Perfect hash table for finding keywords.
 *   This file is machine generated by KeywordTableGen.py at Sat Mar 19 21:01:39 2022. DO NOT EDIT.
 *
 * Copyright (c) 2019~2021 numver8638(신진환, Jinhwan Shin)
 * Released under the MIT License.
 * See the LICENSE file in the project root to get more information.
 */
#include <BuildScript/Compiler/Parse/Lexer.h>

using namespace BuildScript;

#define MIN_WORD_LENGTH 2
#define MAX_WORD_LENGTH 9
#define MAX_HASH_VALUE 139

static size_t GetIndex(const std::string& str) {
    static const unsigned char asso_values[] = {
        140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140, 140, 140, 140,
        140, 140, 140, 140, 140, 140, 140,   0,  62,  59,
          4,   0,  35,   2,   1,   7, 140,   6,  75,  61,
         22,   4,  65, 140,  15,   0,   5,  32,   1,   0,
         67, 140, 140, 140, 140, 140, 140, 140
    };

    auto hval = str.length();

    switch (hval) {
        default:
            hval += asso_values[static_cast<char>(str[3])];
            /*[[fallthrough]]*/
        case 3:
        case 2:
            hval += asso_values[static_cast<char>(str[1])];
            /*[[fallthrough]]*/
        case 1:
            hval += asso_values[static_cast<char>(str[0])];
            /*[[fallthrough]]*/
            break;
    }

    return hval;
}

// static
TokenType Lexer::GetKeyword(const std::string& str) {
    static const struct {
        const char* Name;
        TokenType   Type;
    } wordlist[] = {
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "as", TokenType::As },
        { "set", TokenType::Set },
        { "var", TokenType::Var },
        { "get", TokenType::Get },
        { "assert", TokenType::Assert },
        { "def", TokenType::Def },
        { "", TokenType::Identifier },
        { "is", TokenType::Is },
        { "do", TokenType::Do },
        { "default", TokenType::Default },
        { "with", TokenType::With },
        { "dependsOn", TokenType::DependsOn },
        { "doLast", TokenType::DoLast },
        { "task", TokenType::Task },
        { "static", TokenType::Static },
        { "", TokenType::Identifier },
        { "defined", TokenType::Defined },
        { "", TokenType::Identifier },
        { "raise", TokenType::Raise },
        { "or", TokenType::Or },
        { "doFirst", TokenType::DoFirst },
        { "try", TokenType::Try },
        { "true", TokenType::True },
        { "and", TokenType::And },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "not", TokenType::Not },
        { "none", TokenType::None },
        { "in", TokenType::In },
        { "deinit", TokenType::Deinit },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "super", TokenType::Super },
        { "init", TokenType::Init },
        { "self", TokenType::Self },
        { "false", TokenType::False },
        { "subscript", TokenType::Subscript },
        { "for", TokenType::For },
        { "", TokenType::Identifier },
        { "if", TokenType::If },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "finally", TokenType::Finally },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "return", TokenType::Return },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "case", TokenType::Case },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "inputs", TokenType::Inputs },
        { "const", TokenType::Const },
        { "pass", TokenType::Pass },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "except", TokenType::Except },
        { "extends", TokenType::Extends },
        { "", TokenType::Identifier },
        { "continue", TokenType::Continue },
        { "export", TokenType::Export },
        { "import", TokenType::Import },
        { "else", TokenType::Else },
        { "", TokenType::Identifier },
        { "while", TokenType::While },
        { "break", TokenType::Break },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "outputs", TokenType::Outputs },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "from", TokenType::From },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "match", TokenType::Match },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "", TokenType::Identifier },
        { "class", TokenType::Class },
    };

    if (str.length() <= MAX_WORD_LENGTH && str.length() >= MIN_WORD_LENGTH) {
        auto key = GetIndex(str);

        if (key <= MAX_HASH_VALUE) {
            auto& word = wordlist[key];

            return str == word.Name ? word.Type : TokenType::Identifier;
        }
    }

    return TokenType::Identifier;
}